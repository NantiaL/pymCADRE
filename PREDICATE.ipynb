{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32327326",
   "metadata": {},
   "source": [
    "## PREDICATE: Predictor of Antiviral Targets\n",
    "\n",
    "Predict metabolic host-based enzymatic targets of a one or more viral genome sequences of a single virus.\n",
    "\n",
    "### Steps:\n",
    "- Introduce amino acid mutations to reference protein sequence\n",
    "- Knock-out experiments\n",
    "- Host-derived enforcement \n",
    "- In case of multiple input sequences: Take for each target mean of predicted inhibitory effect over input sequences\n",
    "- Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733952fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cobra\n",
    "from cobra import Model, Reaction, Metabolite\n",
    "from cobra.flux_analysis import single_reaction_deletion\n",
    "from cobra.flux_analysis import flux_variability_analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc0510",
   "metadata": {},
   "source": [
    "#### Define constant variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please provide paths to your input files in the empty strings\n",
    "\n",
    "# name for output files\n",
    "variant_name = ' '\n",
    "\n",
    "# one or more mutated nucleotide sequences\n",
    "fasta_sequences_file = ' '\n",
    "\n",
    "# contain mutation info as extracted from GISAID \n",
    "# (optional; in case reference nucleotide sequence is used the variable is defined as empty string)\n",
    "csv_table = ' '\n",
    "\n",
    "# reference (not mutated) sequence\n",
    "ref_rec = list(SeqIO.parse(' ', \"fasta\"))\n",
    "\n",
    "# metabolic network in SBML format\n",
    "model = cobra.io.read_sbml_model(' ')\n",
    "\n",
    "# reference protein sequence \n",
    "records = list(SeqIO.parse(' ', \"fasta\"))\n",
    "\n",
    "# ids of known structural proteins\n",
    "structural = ['lcl|NC_045512.2_prot_YP_009724390.1_3', 'lcl|NC_045512.2_prot_YP_009724392.1_5', \n",
    "              'lcl|NC_045512.2_prot_YP_009724393.1_6', 'lcl|NC_045512.2_prot_YP_009724397.2_11']\n",
    "\n",
    "# amino acids\n",
    "amino_acids = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', \n",
    "               'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "\n",
    "# modelcular weights of amino acids, taken from CheBI\n",
    "molecular_weight = [89.1, 174.2, 132.1, 133.1, 121.2, 147.1, 146.2, 75.1, 155.2, 131.2, 131.2, \n",
    "                    146.2, 149.2, 165.2, 115.1, 105.1, 119.1, 204.2, 181.2, 117.1]\n",
    "\n",
    "# Copy numbers of structural and non-structural proteins\n",
    "Cs = 120\n",
    "Ce = 20\n",
    "Cn = 456\n",
    "Cm = 1000\n",
    "Cnp = 1\n",
    "\n",
    "# genome copy number\n",
    "Cg = 1 \n",
    "\n",
    "# 4 ATP molecules are needed for the polymerization of amino acids\n",
    "kATP = 4 \n",
    "\n",
    "# 1 PPI molecule is needed to bond two nulceotides\n",
    "kppi = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93a515",
   "metadata": {},
   "source": [
    "#### Create directory to store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a70a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test_Results/\"\n",
    "\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338e4ac",
   "metadata": {},
   "source": [
    "#### Store all input sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2bbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sequences = {}\n",
    "\n",
    "# read fasta file\n",
    "fasta_sequences = SeqIO.parse(open(fasta_sequences_file),'fasta')\n",
    "\n",
    "for fasta in fasta_sequences:\n",
    "    \n",
    "    # store sequence id and sequence\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    \n",
    "    # add info to dictionary\n",
    "    all_sequences[name] = sequence\n",
    "    \n",
    "print(all_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa5e16",
   "metadata": {},
   "source": [
    "#### Analyse nucleotide counts and type of mutations + visualize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if multiple input sequences \n",
    "if csv_table != \" \":\n",
    "    \n",
    "    # extract mutations info\n",
    "    data_df = pd.read_table(csv_table,sep=';')\n",
    "    print(\"data_df: \", data_df)\n",
    "    \n",
    "    # create df to store nucleotides count\n",
    "    nucleotide_counts_df = pd.DataFrame(columns=['GISAID Accession ID', 'A','T','G','C'])\n",
    "\n",
    "    for name, seq in all_sequences.items():\n",
    "\n",
    "        new_row = {'GISAID Accession ID':data_df.loc[data_df['strain']==name]['gisaid_epi_isl'].values[0], 'A':seq.count(\"A\"), 'T':seq.count(\"T\"), 'G':seq.count(\"G\"),'C':seq.count(\"C\")}\n",
    "        nucleotide_counts_df = nucleotide_counts_df.append(new_row, ignore_index=True)\n",
    "\n",
    "    nucleotide_counts_df = nucleotide_counts_df.sort_values(by=[\"A\",\"T\",\"G\",\"C\"])\n",
    "\n",
    "    ################################################################################################\n",
    "    # Additional (optional) Calculations: calculate log2FC between mutated and not-mutated sequence\n",
    "    ################################################################################################\n",
    "    ref_seq = ref_rec[0].seq\n",
    "\n",
    "    ref_seq_ncl_counts = [ref_seq.count(\"A\"),ref_seq.count(\"T\"),ref_seq.count(\"G\"),ref_seq.count(\"C\")]\n",
    "    print(\"ref_seq_ncl_counts:\", ref_seq_ncl_counts)\n",
    "\n",
    "    log2FC_A,log2FC_T,log2FC_G,log2FC_C = [],[],[],[]\n",
    "    for index,row in nucleotide_counts_df.iterrows():\n",
    "\n",
    "        log2FC_A.append(np.log2(row['A']/ref_seq_ncl_counts[0]))\n",
    "        log2FC_T.append(np.log2(row['T']/ref_seq_ncl_counts[1]))\n",
    "        log2FC_G.append(np.log2(row['G']/ref_seq_ncl_counts[2]))\n",
    "        log2FC_C.append(np.log2(row['C']/ref_seq_ncl_counts[3]))\n",
    "\n",
    "    nucleotide_counts_df['log2FC_A'] = log2FC_A\n",
    "    nucleotide_counts_df['log2FC_T'] = log2FC_T\n",
    "    nucleotide_counts_df['log2FC_G'] = log2FC_G\n",
    "    nucleotide_counts_df['log2FC_C'] = log2FC_C\n",
    "    \n",
    "    print(\"nucleotide_counts_df: \", nucleotide_counts_df)\n",
    "    \n",
    "        \n",
    "    ##########################\n",
    "    # Plot nucleotide counts\n",
    "    ##########################\n",
    "    mpl.rcParams['axes.spines.right'] = False\n",
    "\n",
    "    plt.rcParams['font.size'] = '16'\n",
    "\n",
    "    nucleotide_counts_df[['GISAID Accession ID','log2FC_A','log2FC_T','log2FC_G','log2FC_C']].plot(x='GISAID Accession ID',\n",
    "            kind='bar',\n",
    "            stacked=False,\n",
    "            figsize=(19,10),\n",
    "            color=[\"#d7191c\", \"#fdae61\", \"#abdda4\", \"#2b83ba\"],\n",
    "            width=0.7)\n",
    "\n",
    "    plt.axhline(0.0, color='k', linewidth=1.2)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xticks(rotation=89)\n",
    "    plt.ylabel(\"Counts\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(path+\"all_sequences_nucleotides_counts_with_log2FC.pdf\")\n",
    "    plt.savefig(path+\"all_sequences_nucleotides_counts_with_log2FC.png\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    ########################\n",
    "    # Analyse Mutations\n",
    "    #######################\n",
    "    mutation_data = data_df['AA Mutations']\n",
    "    print(\"mutation_data: \", mutation_data)\n",
    "    \n",
    "    # Important check: do all mutations involve letters related to amino acids or involve also \"unknown\" letters\n",
    "    # allowed: all amino acid letters + del, stop, ins, dupl words + numbers\n",
    "    allowed_chars = amino_acids+['s','t','o','p','d','e','l','i','n','s','u']+['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "    c = 0\n",
    "    for d in mutation_data:\n",
    "\n",
    "        for m in d.split(\",\"):\n",
    "\n",
    "            for char in m.strip().split(\" \")[1]:\n",
    "\n",
    "                if char not in allowed_chars:\n",
    "\n",
    "                    # print character and index of occured sequence\n",
    "                    print('weird char detected: ', char, c)\n",
    "        c+=1\n",
    "    \n",
    "    \n",
    "    mutations_df = pd.DataFrame(columns=['Virus Name', 'GISAID Accession ID', 'Mutations'])\n",
    "\n",
    "    mutations_df['Virus Name'] = data_df['strain']\n",
    "    mutations_df['GISAID Accession ID'] = data_df['gisaid_epi_isl']\n",
    "    mutations_df['Mutations'] = data_df['AA Mutations']\n",
    "    mutations_df.to_csv(path+\"mutations_info_\"+variant_name+\"_mean_VBOF.csv\")\n",
    "    print('mutation_df: ', mutations_df)\n",
    "\n",
    "\n",
    "    # store types of mutations observed in the 20 downloaded sequences\n",
    "    mut_types = []\n",
    "\n",
    "    for data in mutation_data:\n",
    "\n",
    "        for mut in data.split(\",\"):\n",
    "\n",
    "            if mut.strip() not in mut_types:\n",
    "\n",
    "                mut_types.append(mut.strip())\n",
    "\n",
    "    print('\\nmut_types: ', mut_types)\n",
    "\n",
    "    # count how oft a mutation appears\n",
    "    mut_frequencies = {}\n",
    "    for mut in mut_types:\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for data in mutation_data:\n",
    "\n",
    "            if mut in data:\n",
    "\n",
    "                count +=1\n",
    "\n",
    "        mut_frequencies[mut] = count\n",
    "\n",
    "    mut_frequencies = dict(sorted(mut_frequencies.items(), key=lambda item: item[1]))\n",
    "    print('\\nmut_frequencies: ', mut_frequencies)\n",
    "    \n",
    "        \n",
    "    ##############################\n",
    "    # Plot Mutations Information\n",
    "    ##############################\n",
    "    plt.figure(figsize=(19,8)).gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.rcParams['font.size'] = '19'\n",
    "\n",
    "    names = list(mut_frequencies.keys())\n",
    "    values = list(mut_frequencies.values())\n",
    "\n",
    "    barplot = plt.bar(range(len(mut_frequencies)), values, tick_label=names, color=\"#d7191c\")\n",
    "\n",
    "    # highlight different mutations\n",
    "    for key,value in mut_frequencies.items():\n",
    "\n",
    "        if 'del' in key:\n",
    "            barplot[list(mut_frequencies).index(key)].set_color('#3288bd')\n",
    "\n",
    "        if 'stop' in key:\n",
    "            barplot[list(mut_frequencies).index(key)].set_color('#99d594')\n",
    "\n",
    "        if 'ins' in key:\n",
    "            barplot[list(mut_frequencies).index(key)].set_color('#fc8d59')\n",
    "\n",
    "        if 'dupl' in key:\n",
    "            barplot[list(mut_frequencies).index(key)].set_color('#984ea3')\n",
    "\n",
    "\n",
    "    plt.xlim([-0.9,len(mut_frequencies)])\n",
    "    plt.ylim([0,21])\n",
    "\n",
    "    plt.xticks(rotation=89)\n",
    "\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.xlabel(\"Mutation Type\")\n",
    "\n",
    "    blue_patch = mpatches.Patch(color='#3288bd', label='Deletions')\n",
    "    green_patch = mpatches.Patch(color='#99d594', label='Involves stop codon')\n",
    "    plt.legend(handles=[blue_patch, green_patch])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(path+variant_name+\"_sequences_mutation_counts.pdf\")\n",
    "    plt.savefig(path+variant_name+\"_sequences_mutation_counts.png\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    ###########################################\n",
    "    # Plot Mutations Information per category\n",
    "    ###########################################\n",
    "    # store mutations per protein\n",
    "    spike_prot_muts, n_prot_muts, m_prot_muts, e_prot_muts,nsp_prot_muts, ns_prot_muts = {},{},{},{},{},{}\n",
    "\n",
    "    for key, value in mut_frequencies.items():\n",
    "        if \"Spike\" in key:\n",
    "            spike_prot_muts[key.split(\"Spike\")[1].strip()] = value\n",
    "\n",
    "        elif \"N \" in key:\n",
    "            n_prot_muts[key.split(\"N\")[1].strip()] = value\n",
    "\n",
    "        elif \"M \" in key:\n",
    "            m_prot_muts[key.split(\"M\")[1].strip()] = value\n",
    "\n",
    "        elif \"E \" in key:\n",
    "            e_prot_muts[key.split(\"E\")[1].strip()] = value\n",
    "\n",
    "        elif \"NSP\" in key:\n",
    "            nsp_prot_muts[key] = value\n",
    "\n",
    "        else:\n",
    "            ns_prot_muts[key] = value\n",
    "\n",
    "    print(\"spike_prot_muts\", spike_prot_muts)\n",
    "    print(\"n_prot_muts\", n_prot_muts)\n",
    "    print(\"m_prot_muts\", m_prot_muts)\n",
    "    print(\"e_prot_muts\", e_prot_muts)\n",
    "    print(\"nsp_prot_muts\", nsp_prot_muts)\n",
    "    print(\"ns_prot_muts\", ns_prot_muts)\n",
    "    print(\"\\n Total length\", len(mut_frequencies))\n",
    "    print(\"\\n Total length\", len(spike_prot_muts)+len(n_prot_muts)+len(m_prot_muts)+ len(e_prot_muts)+ len(nsp_prot_muts)+ len(ns_prot_muts))\n",
    "    \n",
    "    \n",
    "    plt.rcParams['font.size'] = 18\n",
    "    plt.rcParams['xtick.labelsize'] = 18\n",
    "\n",
    "    colors=[\"#d53e4f\", \"#fc8d59\", \"#fee08b\", \"#e6f598\", \"#99d594\", \"#3288bd\"]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(30, 20), sharey=True)\n",
    "\n",
    "    plt.subplots_adjust(left=0.125,\n",
    "                        bottom=0.1, \n",
    "                        right=0.9, \n",
    "                        top=0.9, \n",
    "                        wspace=0.2, \n",
    "                        hspace=0.35)\n",
    "\n",
    "    sns.barplot(ax=axes[0,0], x=list(spike_prot_muts.keys()), y=list(spike_prot_muts.values()),color=colors[0])\n",
    "    axes[0,0].set_title(\"Spike Protein\", fontweight=\"bold\")\n",
    "    axes[0,0].set_xticklabels(list(spike_prot_muts.keys()), rotation=90)\n",
    "\n",
    "    sns.barplot(ax=axes[0,1], x=list(n_prot_muts.keys()), y=list(n_prot_muts.values()), color=colors[1])\n",
    "    axes[0,1].set_title(\"N Protein\", fontweight=\"bold\")\n",
    "    axes[0,1].set_xticklabels(list(n_prot_muts.keys()), rotation=90)\n",
    "\n",
    "    sns.barplot(ax=axes[0,2], x=list(m_prot_muts.keys()), y=list(m_prot_muts.values()), color=colors[2])\n",
    "    axes[0,2].set_title(\"Membrane Protein\", fontweight=\"bold\")\n",
    "    axes[0,2].set_xticklabels(list(m_prot_muts.keys()), rotation=90)\n",
    "\n",
    "    if len(e_prot_muts) != 0:\n",
    "        # ! omit if no mutation on the E protein found (e.g., in gamma SARS-CoV-2 variant)\n",
    "        sns.barplot(ax=axes[1,0], x=list(e_prot_muts.keys()), y=list(e_prot_muts.values()), color=colors[3])\n",
    "        axes[1,0].set_title(\"Envelope Protein\", fontweight=\"bold\")\n",
    "        axes[1,0].set_xticklabels(list(e_prot_muts.keys()), rotation=90)\n",
    "\n",
    "    sns.barplot(ax=axes[1,1], x=list(nsp_prot_muts.keys()), y=list(nsp_prot_muts.values()), color=colors[4])\n",
    "    axes[1,1].set_title(\"NSP Proteins\",fontweight=\"bold\")\n",
    "    axes[1,1].set_xticklabels(list(nsp_prot_muts.keys()), rotation=90)\n",
    "\n",
    "    sns.barplot(ax=axes[1,2], x=list(ns_prot_muts.keys()), y=list(ns_prot_muts.values()), color=colors[5])\n",
    "    axes[1,2].set_title(\"NS Ptoteins\", fontweight=\"bold\")\n",
    "    axes[1,2].set_xticklabels(list(ns_prot_muts.keys()), rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(path+variant_name+\"_sequences_mutation_counts_alltogether.pdf\")\n",
    "    plt.savefig(path+variant_name+\"_sequences_mutation_counts_alltogether.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# if only one input sequence, simply count nucleotides\n",
    "else:\n",
    "    \n",
    "    nuc_seq = list(all_sequences.values())[0]\n",
    "    print(\"A: \", nuc_seq.count(\"A\"))\n",
    "    print(\"T: \", nuc_seq.count(\"T\"))\n",
    "    print(\"G: \", nuc_seq.count(\"G\"))\n",
    "    print(\"C: \", nuc_seq.count(\"C\"))\n",
    "    print(\"Total length: \",len(seq))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_derived_enforcement(model, vbof_name, bof_name, growth_rate_vbof, growth_rate_bof):\n",
    "    \n",
    "    \"\"\" \n",
    "    Host-derived Enforcement\n",
    "    \n",
    "    Inputs:\n",
    "        - model: SBML model \n",
    "        - vbof_name: string of vbof ID in given model\n",
    "        - bof_name: string of bof ID in given model\n",
    "        - growth_rate_vbof: virus growth rate \n",
    "        - growth_rate_bof: host maintenance rate\n",
    "        \n",
    "    Outputs:\n",
    "        - data: list of lists with all predicted targets and the respective % reamining BOF\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    model.objective=bof_name\n",
    "    print('BOF optimized:', model.optimize().objective_value)\n",
    "    fva_mac = flux_variability_analysis(model,fraction_of_optimum=0.98)\n",
    "    fva_mac =fva_mac.reset_index()\n",
    "    fva_mac = fva_mac.rename(columns={'index': 'Reaction_ID', 'minimum': 'H_(F-)', 'maximum': 'H_(F+)'})\n",
    "\n",
    "    model.objective=vbof_name\n",
    "    print('VBOF optimized:', model.optimize().objective_value)\n",
    "    fva_vbof = flux_variability_analysis(model,fraction_of_optimum=0.75)\n",
    "    fva_vbof =fva_vbof.reset_index()\n",
    "    fva_vbof = fva_vbof.rename(columns={'index': 'Reaction_ID', 'minimum': 'V_(F-)', 'maximum': 'V_(F+)'})\n",
    "\n",
    "    fva = fva_mac.merge(fva_vbof, left_on='Reaction_ID', right_on='Reaction_ID')\n",
    "    fba_vbof_fluxes = model.optimize().fluxes\n",
    "\n",
    "    hde = {}\n",
    "    zero_fba_vbof_flux = []\n",
    "\n",
    "    for i in range(len(fva)):\n",
    "\n",
    "        if fva.loc[i]['H_(F+)'] == fva.loc[i]['V_(F+)'] and fva.loc[i]['H_(F-)'] == fva.loc[i]['V_(F-)']:\n",
    "            continue\n",
    "\n",
    "        elif fva.loc[i]['H_(F+)'] > fva.loc[i]['V_(F+)'] and fva.loc[i]['H_(F-)'] >= fva.loc[i]['V_(F-)']:\n",
    "            new_lower_bound = fva.loc[i]['H_(F+)'] - ((fva.loc[i]['H_(F+)']-fva.loc[i]['V_(F+)'])/2)\n",
    "            new_upper_bound = fva.loc[i]['H_(F+)']\n",
    "\n",
    "        elif fva.loc[i]['H_(F-)'] < fva.loc[i]['V_(F-)'] and fva.loc[i]['H_(F+)'] <= fva.loc[i]['V_(F+)']:\n",
    "            new_lower_bound = fva.loc[i]['H_(F-)']\n",
    "            new_upper_bound = fva.loc[i]['H_(F-)'] - ((fva.loc[i]['H_(F-)']-fva.loc[i]['V_(F-)'])/2)\n",
    "\n",
    "        elif fva.loc[i]['H_(F-)'] > fva.loc[i]['V_(F-)'] and fva.loc[i]['H_(F+)'] < fva.loc[i]['V_(F+)']:\n",
    "            new_lower_bound = fva.loc[i]['H_(F-)']\n",
    "            new_upper_bound = fva.loc[i]['H_(F+)']\n",
    "\n",
    "        elif fva.loc[i]['H_(F-)'] >= fva.loc[i]['V_(F-)'] and fva.loc[i]['H_(F+)'] <= fva.loc[i]['V_(F+)']:\n",
    "            new_upper_bound = fva.loc[i]['H_(F+)'] - ((fva.loc[i]['H_(F+)']-fva.loc[i]['V_(F+)'])/2)\n",
    "            new_lower_bound = fva.loc[i]['H_(F-)'] - ((fva.loc[i]['H_(F-)']-fva.loc[i]['V_(F-)'])/2)   \n",
    "\n",
    "        else:\n",
    "            print('else: ', fva.loc[i]['Reaction_ID'])\n",
    "\n",
    "\n",
    "        with model: \n",
    "            # store old (initial) reaction bounds\n",
    "            old_lb = model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).lower_bound\n",
    "            old_ub = model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).upper_bound\n",
    "\n",
    "            direction_before = model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).reaction.split(\" \")\n",
    "\n",
    "            # ensure that lower bound will always be < than upper bound\n",
    "            if new_lower_bound > new_upper_bound:\n",
    "                model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).lower_bound = round(new_upper_bound,6)\n",
    "                model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).upper_bound = round(new_lower_bound,6)\n",
    "            else:\n",
    "                model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).lower_bound = round(new_lower_bound,6)\n",
    "                model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).upper_bound = round(new_upper_bound,6)\n",
    "\n",
    "            direction_after = model.reactions.get_by_id(fva.loc[i]['Reaction_ID']).reaction.split(\" \")\n",
    "\n",
    "            # optimize BOF \n",
    "            model.objective = bof_name\n",
    "            host = model.optimize().objective_value\n",
    "            # optimize VBOF \n",
    "            model.objective = vbof_name\n",
    "            virus = model.optimize().objective_value\n",
    "                    \n",
    "            # report reactions that reduce the virus growth rate to below 50% of its initial growth rate\n",
    "            if virus < 0.5*growth_rate_vbof:\n",
    "                \n",
    "                print(direction_before,direction_after)\n",
    "\n",
    "\n",
    "                if fba_vbof_fluxes[fva.loc[i]['Reaction_ID']] == 0.0:\n",
    "\n",
    "                    # ignore those, since they don't influence the virus's growth\n",
    "                    print('Zero FBA flux when VBOF optimized: ', fva.loc[i]['Reaction_ID'])\n",
    "                    zero_fba_vbof_flux.append(fva.loc[i]['Reaction_ID'])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if  new_lower_bound >= 0 and new_upper_bound > 0:\n",
    "                        hde[fva.loc[i]['Reaction_ID']] = [host, virus]\n",
    "                        print('old bounds:', old_lb, old_ub)\n",
    "                        print('Forward:', fva.loc[i]['Reaction_ID'], new_lower_bound, new_upper_bound)\n",
    "\n",
    "                    elif new_lower_bound < 0 and new_upper_bound <= 0:\n",
    "                        hde[fva.loc[i]['Reaction_ID']] = [host, virus]\n",
    "                        print('old bounds:', old_lb, old_ub)\n",
    "                        print('Reverse:', fva.loc[i]['Reaction_ID'], new_lower_bound, new_upper_bound)\n",
    "\n",
    "                    elif new_lower_bound < 0 and new_upper_bound > 0:\n",
    "                        hde[fva.loc[i]['Reaction_ID']] = [host, virus]\n",
    "                        print('old bounds:', old_lb, old_ub)\n",
    "                        print('Both directions:', fva.loc[i]['Reaction_ID'], new_lower_bound, new_upper_bound)\n",
    "\n",
    "                    else:\n",
    "                        print('old bounds:', old_lb, old_ub)\n",
    "                        print('Unknown:', fva.loc[i]['Reaction_ID'], new_lower_bound, new_upper_bound)\n",
    "                    \n",
    "                print(\"------------------------------------------\")        \n",
    "\n",
    "    \n",
    "    # remove BOF and VBOF if appear in targets\n",
    "    if vbof_name in hde:\n",
    "        hde.pop(vbof_name)\n",
    "    if bof_name in hde:\n",
    "        hde.pop(bof_name)\n",
    "        \n",
    "\n",
    "    print('Total HDE targets', len(hde))\n",
    "    print() \n",
    "    \n",
    "    hde_vbof = {}\n",
    "    for key in hde.keys():\n",
    "        hde_vbof[key] = (hde[key][1]/growth_rate_vbof)*100\n",
    "    \n",
    "    hde_vbof = {k: v for k, v in sorted(hde_vbof.items(), key=lambda item: item[1])}\n",
    "    \n",
    "    data = [[key, hde_vbof[key]] for key in hde_vbof.keys()]\n",
    "    print('HDE Targets sorted:', data)\n",
    "    print()\n",
    "    print('HDE - top first target:', data[0])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba4ac5",
   "metadata": {},
   "source": [
    "#### Create VBOFs + introduce AA mutations + target prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fdfce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_iterations = 0\n",
    "\n",
    "# store stoichiometric coefficients of all VBOF compounds of all input sequences\n",
    "stoichiometric_coeffs = {} \n",
    "\n",
    "# store results of KO and HDE experiments of all input sequences\n",
    "ko_results_all_sequences, hde_results_all_sequences = {}, {} \n",
    "\n",
    "# store all counts from all input sequences\n",
    "amino_acids_counts = {}\n",
    "\n",
    "for aa in amino_acids:\n",
    "    amino_acids_counts[aa] = []\n",
    "\n",
    "# for all input sequences\n",
    "for ids, seq in all_sequences.items():\n",
    "    \n",
    "    nucl_aa = [] # store counts of nucleotides and amino acids in the current sequence\n",
    "    \n",
    "    print(f\"Seq.Nr. {count_iterations}\")\n",
    "    print(f\"Seq.ID. {ids}\")\n",
    "    \n",
    "    count_dict = {}\n",
    "    \n",
    "    #********************************************\n",
    "    # Nucleotides Investment\n",
    "    #********************************************\n",
    "    \n",
    "    # count nucleotides in all sequences\n",
    "    A, U, G, C = 0, 0, 0, 0\n",
    "\n",
    "    # Get nucleotide count from .fasta file\n",
    "    A = seq.count('A')\n",
    "    U = seq.count('T')\n",
    "    G = seq.count('G')\n",
    "    C = seq.count('C')\n",
    "    print(\"A,U,G,C: \",A,U,G,C)\n",
    "\n",
    "    # compute moles of each nulceotide in a mole of virus particle\n",
    "    AUtot = Cg*2*(A + U)\n",
    "    GCtot = Cg*2*(G + C)\n",
    "    print('AUtot: ', AUtot)\n",
    "    print('GCtot: ', GCtot)\n",
    "\n",
    "    # convert moles of nucleotides into grams of nucleotide per mole of virus\n",
    "    GA = AUtot*135.13\n",
    "    GU = AUtot*112.09\n",
    "    GG = GCtot*151.13\n",
    "    GC = GCtot*111.1\n",
    "\n",
    "    # compute the mass of all genome components\n",
    "    Gi = GA+GU+GG+GC\n",
    "    print('Gi: ',Gi)    \n",
    "    \n",
    "\n",
    "    # Count Amino Acids in proteins\n",
    "    for letter in amino_acids:\n",
    "        num = 0\n",
    "        for i in range(len(records)):\n",
    "            if records[i].id == 'lcl|NC_045512.2_prot_YP_009724390.1_3': #spike\n",
    "                num += records[i].seq.count(letter)*Cs\n",
    "            elif records[i].id == 'lcl|NC_045512.2_prot_YP_009724392.1_5': #envelope\n",
    "                num += records[i].seq.count(letter)*Ce\n",
    "            elif records[i].id == 'lcl|NC_045512.2_prot_YP_009724393.1_6': #membrane\n",
    "                num += records[i].seq.count(letter)*Cm\n",
    "            elif records[i].id == 'lcl|NC_045512.2_prot_YP_009724397.2_11': #nucleocapsid\n",
    "                num += records[i].seq.count(letter)*Cn\n",
    "            else:\n",
    "                num += records[i].seq.count(letter) \n",
    "        \n",
    "        # for current amino acid\n",
    "        count_dict[letter] = [num]\n",
    "\n",
    "    # **********************************************************\n",
    "    # Introduce Mutations in reference protein sequence \n",
    "    # **********************************************************   \n",
    "    # if table with mutations is given\n",
    "    if csv_table != \" \":\n",
    "        \n",
    "        for mut in list(data_df[data_df['strain']==ids]['AA Mutations'])[0].split(\",\"):\n",
    "\n",
    "            if 'del' in mut or 'stop' in mut:\n",
    "\n",
    "                to_delete = mut.strip().split(\" \")[1][0]\n",
    "\n",
    "                # consider different weights of structural proteins when deleting/inserting amino acid\n",
    "                if 'Spike' in mut:\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Cs\n",
    "                elif \"E \" in mut: #e\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Ce\n",
    "                elif \"M \" in mut: #m\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Cm\n",
    "                elif \"N \" in mut: #n\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Cn\n",
    "                else:\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - 1   \n",
    "\n",
    "            elif 'ins' in mut or 'dupl' in mut:\n",
    "\n",
    "                to_delete = mut.strip().split(\" \")[1][0]\n",
    "\n",
    "                # consider differnt weights of structural proteins when deleting/inserting amino acid\n",
    "                if 'Spike' in mut:\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] + Cs\n",
    "                elif \"E \" in mut: #e\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] + Ce\n",
    "                elif \"M \" in mut: #m\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] + Cm\n",
    "                elif \"N \" in mut: #n\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] + Cn\n",
    "                else:\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] + 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                to_delete = \"\".join(filter(str.isupper, mut.strip().split(\" \")[1]))[0]\n",
    "                to_add = \"\".join(filter(str.isupper, mut.strip().split(\" \")[1]))[1]\n",
    "\n",
    "                # consider differnt weights of structural proteins when deleting/inserting amino acid\n",
    "                if 'Spike' in mut:\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Cs\n",
    "                    count_dict[to_add][0] = count_dict[to_add][0] + Cs\n",
    "                elif \"E \" in mut: #e\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Ce\n",
    "                    count_dict[to_add][0] = count_dict[to_add][0] + Ce\n",
    "                elif \"M \" in mut: #m\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Cm\n",
    "                    count_dict[to_add][0] = count_dict[to_add][0] + Cm\n",
    "\n",
    "                elif \"N \" in mut: #n\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - Cn\n",
    "                    count_dict[to_add][0] = count_dict[to_add][0] + Cn\n",
    "                else:\n",
    "                    count_dict[to_delete][0] = count_dict[to_delete][0] - 1\n",
    "                    count_dict[to_add][0] = count_dict[to_add][0] + 1\n",
    "    \n",
    "    # store counts of amino acids\n",
    "    for keys, values in count_dict.items():\n",
    "        amino_acids_counts[keys].append(values[0])\n",
    "    \n",
    "    # ********************************************\n",
    "    # Amino Acid Investment\n",
    "    # ********************************************\n",
    "    \n",
    "    for letter, weight in zip(amino_acids, molecular_weight):\n",
    "        count_dict[letter].append(count_dict[letter][0]*weight) \n",
    "    \n",
    "    # Compute mass of all proteome components\n",
    "    Gj = 0    \n",
    "    for letter in amino_acids:\n",
    "        Gj += count_dict[letter][1]\n",
    "\n",
    "    print('Gj: ', Gj)\n",
    "    \n",
    "    #**********************\n",
    "    # Total Viral Mass\n",
    "    #**********************\n",
    "    Mv = Gi+Gj\n",
    "    print('Mv: ', Mv)\n",
    "\n",
    "\n",
    "    SA = 1000*(AUtot/Mv) #stoichiometric coefficient of Adenine\n",
    "    SG = 1000*(GCtot/Mv) #stoichiometric coefficient of Guanine\n",
    "    print(\"SA: \", SA)\n",
    "    print(\"SG: \", SG)\n",
    "\n",
    "    for letter in amino_acids:\n",
    "        count_dict[letter].append(1000*(count_dict[letter][0]/Mv)) #entry 4 = SjX\n",
    "\n",
    "    #**********************\n",
    "    # ATP Requirement\n",
    "    #**********************\n",
    "\n",
    "    new_count_dict = count_dict\n",
    "    Xj = 0\n",
    "    for letter in amino_acids:\n",
    "        Xj += count_dict[letter][0]\n",
    "\n",
    "    ATOT = (Xj * kATP) - kATP\n",
    "    SATP = 1000*(ATOT/Mv)\n",
    "    print('SATP: ', SATP)\n",
    "\n",
    "    #*****************************\n",
    "    # Pyrophosphate Liberation\n",
    "    #*****************************\n",
    "    PG = ((A + U + G + C)*kppi) - kppi\n",
    "    PR = ((A + U + G + C)*kppi) - kppi\n",
    "\n",
    "    PTOT = Cg*(PG+PR)\n",
    "\n",
    "    SPPi = 1000*(PTOT/Mv)\n",
    "    print('SPPi: ', SPPi)\n",
    "    \n",
    "    print('Amino acid counts: ', count_dict)\n",
    "    \n",
    "    #***************************************************************\n",
    "    # VBOF Reconstruction + Incorporation in host-virus cell \n",
    "    #***************************************************************\n",
    "    with model: \n",
    "        \n",
    "        # add new VBOF\n",
    "        reaction = Reaction('VBOF')\n",
    "        reaction.name = 'Viral biomass objective function of coronavirus 2019-nCoV'\n",
    "        reaction.lower_bound = 0 \n",
    "        reaction.upper_bound = 1000 \n",
    "\n",
    "        reaction.add_metabolites({\n",
    "            #energy requirements\n",
    "            model.metabolites.get_by_id('adp_c'): SATP,  \n",
    "            model.metabolites.get_by_id('h_c'): SATP,  \n",
    "            model.metabolites.get_by_id('h2o_c'): -SATP,  \n",
    "            model.metabolites.get_by_id('pi_c'): SATP, \n",
    "            model.metabolites.get_by_id('ppi_c'): SPPi, \n",
    "\n",
    "            #nucleotides: left-hand terms \n",
    "            model.metabolites.get_by_id('atp_c'): -(SATP + SA), \n",
    "            model.metabolites.get_by_id('ctp_c'): -SG,\n",
    "            model.metabolites.get_by_id('gtp_c'): -SG,\n",
    "            model.metabolites.get_by_id('utp_c'): -SA,\n",
    "\n",
    "            #amino acids: left-hand terms\n",
    "            model.metabolites.get_by_id('ala__L_c'): -count_dict['A'][2],\n",
    "            model.metabolites.get_by_id('arg__L_c'): -count_dict['R'][2], \n",
    "            model.metabolites.get_by_id('asn__L_c'): -count_dict['N'][2],\n",
    "            model.metabolites.get_by_id('asp__L_c'): -count_dict['D'][2],\n",
    "            model.metabolites.get_by_id('cys__L_c'): -count_dict['C'][2],\n",
    "            model.metabolites.get_by_id('glu__L_c'): -count_dict['E'][2],\n",
    "            model.metabolites.get_by_id('gln__L_c'): -count_dict['Q'][2],\n",
    "            model.metabolites.get_by_id('gly_c'): -count_dict['G'][2],\n",
    "            model.metabolites.get_by_id('his__L_c'): -count_dict['H'][2],\n",
    "            model.metabolites.get_by_id('ile__L_c'): -count_dict['I'][2],\n",
    "            model.metabolites.get_by_id('leu__L_c'): -count_dict['L'][2],\n",
    "            model.metabolites.get_by_id('lys__L_c'): -count_dict['K'][2],\n",
    "            model.metabolites.get_by_id('met__L_c'): -count_dict['M'][2],\n",
    "            model.metabolites.get_by_id('phe__L_c'): -count_dict['F'][2],\n",
    "            model.metabolites.get_by_id('pro__L_c'): -count_dict['P'][2],\n",
    "            model.metabolites.get_by_id('ser__L_c'): -count_dict['S'][2],\n",
    "            model.metabolites.get_by_id('thr__L_c'): -count_dict['T'][2],\n",
    "            model.metabolites.get_by_id('trp__L_c'): -count_dict['W'][2],\n",
    "            model.metabolites.get_by_id('tyr__L_c'): -count_dict['Y'][2],\n",
    "            model.metabolites.get_by_id('val__L_c'): -count_dict['V'][2], \n",
    "            \n",
    "            # add lipids\n",
    "            model.metabolites.pchol_hs_c: 0.038400, \n",
    "            model.metabolites.pe_hs_c: 0.014566, \n",
    "            model.metabolites.pail_hs_c: 0.006621, \n",
    "            model.metabolites.ps_hs_c: 0.001986, \n",
    "            model.metabolites.chsterol_c: 0.000012, \n",
    "            model.metabolites.sphmyln_hs_c: 0.001986 \n",
    "\n",
    "        })\n",
    "\n",
    "        model.add_reactions([reaction])\n",
    "\n",
    "        s_matrix = cobra.util.array.create_stoichiometric_matrix(model=model, array_type='DataFrame')\n",
    "        # store stoichiometric coeffs as absolute values\n",
    "        stoichiometric_coeffs[ids] = list(map(abs,list(s_matrix['VBOF'].loc[s_matrix['VBOF'] != 0])))\n",
    "        # store compounds participating in VBOF\n",
    "        vbof_compounds = list(s_matrix['VBOF'].loc[s_matrix['VBOF'] != 0].index)\n",
    "\n",
    "        print(\"VBOF compounds: \",vbof_compounds)\n",
    "\n",
    "        #***************************************\n",
    "        # Targets Prediction Experiments\n",
    "        #***************************************\n",
    "\n",
    "        # (1) Single reaction knock-out experiments\n",
    "        print(\"\\n * Single Reaction Knock-outs * \\n\")\n",
    "        \n",
    "        # optimize host\n",
    "        model.objective = 'biomass_bec'\n",
    "        growth_rate_bec = model.optimize().objective_value\n",
    "        react_ko_mac = single_reaction_deletion(model)\n",
    "        react_ko_mac = react_ko_mac.rename(columns={'growth': 'growth_host', 'status': 'status_host'})\n",
    "        # change indices from numbers to reaction IDs\n",
    "        new_indices = []\n",
    "        for i in react_ko_mac[\"ids\"]:\n",
    "            new_indices.append(list(i)[0])\n",
    "        react_ko_mac.set_index([pd.Index(new_indices)], inplace=True)\n",
    "\n",
    "        # optimize virus\n",
    "        model.objective = 'VBOF'\n",
    "        growth_rate_vbof = model.optimize().objective_value\n",
    "        react_ko_vbof = single_reaction_deletion(model)\n",
    "        react_ko_vbof = react_ko_vbof.rename(columns={'growth': 'growth_virus', 'status': 'status_virus'})\n",
    "        # change indices from numbers to reaction IDs\n",
    "        new_indices2 = []\n",
    "        for i in react_ko_vbof[\"ids\"]:\n",
    "            new_indices2.append(list(i)[0])\n",
    "        react_ko_vbof.set_index([pd.Index(new_indices2)], inplace=True)\n",
    "\n",
    "        # merge results from BOF and VBOF knock-out\n",
    "        growth_virus = react_ko_vbof[\"growth_virus\"]\n",
    "        merged = react_ko_mac.join(growth_virus)\n",
    "\n",
    "        # for each reaction: calculate what percentage of host growth remains after single reaction knock-out\n",
    "        percent_bec = []\n",
    "        for i in merged.index:\n",
    "            percent_bec.append(merged.loc[i]['growth_host']/growth_rate_bec*100)\n",
    "        merged.insert(loc = 0, column='%growth_host', value=percent_bec)\n",
    "\n",
    "        percent_vbof = []\n",
    "        for i in merged.index:\n",
    "            percent_vbof.append(merged.loc[i]['growth_virus']/growth_rate_vbof*100)     \n",
    "        merged.insert(loc = 0, column='%growth_virus', value=percent_vbof)\n",
    "\n",
    "        # keep only interesting -- > host 99% and virus 0%\n",
    "        print('KO Targets: ', list(merged.loc[(merged['%growth_host'] > 99) & (merged['%growth_virus'] == 0.0)].index))\n",
    "        ko_results_all_sequences[ids] = list(merged.loc[(merged['%growth_host'] > 99) & (merged['%growth_virus'] == 0.0)].index)\n",
    "\n",
    "\n",
    "        #######################################\n",
    "        # Host-derived enforcement\n",
    "        #######################################\n",
    "        hde_results_all_sequences[ids] = host_derived_enforcement(model,'VBOF','biomass_bec',growth_rate_vbof,growth_rate_bec)\n",
    "\n",
    "    print('\\n')\n",
    "    count_iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1308a6",
   "metadata": {},
   "source": [
    "#### Collect all predicted targets + store results + visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1038e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_targets = []\n",
    "\n",
    "for keys,values in hde_results_all_sequences.items():\n",
    "    for lst in values:\n",
    "        all_targets.append(lst[0])\n",
    "\n",
    "# store targest that were predicted for all the input sequences\n",
    "all_unique_targets = list(set(all_targets))\n",
    "print(len(all_unique_targets))\n",
    "print(all_unique_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23107a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes with HDE results for all input sequences\n",
    "if csv_table != \" \":\n",
    "    \n",
    "    merged = pd.DataFrame(columns=all_unique_targets, index=list(hde_results_all_sequences.keys()))\n",
    "\n",
    "    c=1\n",
    "    gisaid_ids = []\n",
    "\n",
    "    for seq_id in all_sequences.keys():\n",
    "\n",
    "        gisaid_ids.append(data_df.loc[data_df['strain'] == seq_id]['gisaid_epi_isl'].item())\n",
    "\n",
    "        seq = hde_results_all_sequences[seq_id]\n",
    "        seq_targets = [l[0] for l in seq]\n",
    "        seq_remaining_virus = [l[1] for l in seq]\n",
    "\n",
    "        seq_df = pd.DataFrame(columns=['Targets', '% remaining VBOF'])\n",
    "        seq_df['Targets'] = seq_targets\n",
    "        seq_df['% remaining VBOF'] = seq_remaining_virus\n",
    "        # sort by target ID\n",
    "        seq_df.sort_values(by=['Targets'], inplace=True)\n",
    "        # store %remaining VBOF in merged df\n",
    "        for r in all_unique_targets:\n",
    "            if r in list(seq_df['Targets']):\n",
    "                merged[r][seq_id] = list(seq_df.loc[seq_df['Targets']==r]['% remaining VBOF'])[0]\n",
    "            else:\n",
    "                merged[r][seq_id] = np.nan\n",
    "\n",
    "        # sort by value\n",
    "        seq_df.sort_values(by=['% remaining VBOF'], inplace=True)\n",
    "\n",
    "        # store as csv file\n",
    "        seq_df.to_csv(path+variant_name+'_seq_'+str(c)+'.csv')\n",
    "\n",
    "        c+=1\n",
    "\n",
    "    merged.index = gisaid_ids\n",
    "\n",
    "    # get mean of targets\n",
    "    mean_of_targets = []\n",
    "    for (columnName, columnData) in merged.iteritems():\n",
    "\n",
    "        mean_of_targets.append(columnData.values.mean())\n",
    "    print('mean_of_targets:', mean_of_targets)\n",
    "\n",
    "    merged = merged.T\n",
    "    merged['Mean'] = mean_of_targets\n",
    "\n",
    "    merged.to_csv(path+variant_name+'_all_merged_HDE_results_'+variant_name+'.csv')\n",
    "\n",
    "    # remove target names form index to be able to acess them below\n",
    "    merged = merged.reset_index()\n",
    "    merged.rename({'index': 'Target'}, axis=1, inplace=True)\n",
    "    print(merged)\n",
    "    \n",
    "    # NaN in mean column means that mean could be computed because \n",
    "    # the reaction for some sequences was not observed as a target\n",
    "    # thus it is not robust.\n",
    "    # --> look only those predicted for all input sequences as targets\n",
    "\n",
    "    robust_targets =merged[merged['Mean'].notna()]\n",
    "    robust_targets.to_csv(path+variant_name+'_robust_targets.csv')\n",
    "    print(robust_targets)\n",
    "    \n",
    "    #######################\n",
    "    # Visualize\n",
    "    #######################\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    robust_targets = robust_targets.sort_values(by='Mean',ascending=False)\n",
    "\n",
    "    plt.bar(robust_targets['Target'], height = robust_targets['Mean'], width = 0.1, color=\"#41b6c4\") \n",
    "    plt.plot(robust_targets['Target'], robust_targets['Mean'], 'o', color=\"#253494\")\n",
    "\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.ylabel(\"% remaining virus growth\", fontsize=14)\n",
    "\n",
    "    plt.xlim([-0.5,len(robust_targets['Target'])])\n",
    "\n",
    "    plt.ylim(31,47)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path+variant_name+'_all_HDE_targets_mean_after_results.pdf')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# if only one sequence in input \n",
    "else:\n",
    "    \n",
    "    targets = [j[0] for i in list(hde_results_all_sequences.values()) for j in i]\n",
    "    remaining_virus = [j[1] for i in list(hde_results_all_sequences.values()) for j in i]\n",
    "    \n",
    "    merged = pd.DataFrame(remaining_virus,targets, columns=['%Remaining_virus'])\n",
    "    merged.to_csv(path+variant_name+'_HDE_targets.csv')\n",
    "    print(merged)\n",
    "    \n",
    "    #######################\n",
    "    # Visualize\n",
    "    #######################\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    sorted_targets = merged.sort_values(by='%Remaining_virus',ascending=False)\n",
    "\n",
    "    plt.bar(list(sorted_targets.index), height = sorted_targets['%Remaining_virus'], width = 0.1, color=\"#41b6c4\") \n",
    "    plt.plot(list(sorted_targets.index), sorted_targets['%Remaining_virus'], 'o', color=\"#253494\")\n",
    "\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.ylabel(\"% remaining virus growth\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path+variant_name+'_all_HDE_targets_mean_after_results.pdf')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "vbof_compounds = ['ala__L_c', 'adp_c', 'arg__L_c', 'asn__L_c', 'asp__L_c', 'atp_c', 'ctp_c', 'cys__L_c', 'gln__L_c', 'glu__L_c', 'gly_c', 'h2o_c', 'h_c', 'gtp_c', 'his__L_c', 'ile__L_c', 'lys__L_c', 'leu__L_c', 'met__L_c', 'pi_c', 'ppi_c', 'pro__L_c', 'phe__L_c', 'ser__L_c', 'thr__L_c', 'tyr__L_c', 'trp__L_c', 'utp_c', 'val__L_c']\n",
    "\n",
    "if csv_table!= \" \":\n",
    "    vbofs_info = pd.DataFrame(stoichiometric_coeffs).T\n",
    "    vbofs_info.columns = vbof_compounds\n",
    "    vbofs_info.index = data_df['gisaid_epi_isl']\n",
    "    vbofs_info.to_csv(path+variant_name+'_all_20_VBOFs_stoich_coeffs_info.csv')\n",
    "    print(vbofs_info)\n",
    "else:\n",
    "    vbofs_info = pd.DataFrame(stoichiometric_coeffs).T\n",
    "    vbofs_info.columns = vbof_compounds\n",
    "    \n",
    "    vbofs_info.to_csv(path+variant_name+'_all_VBOFs_stoich_coeffs_info.csv')\n",
    "\n",
    "    print(vbofs_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ca042",
   "metadata": {},
   "outputs": [],
   "source": [
    "if csv_table!=\" \":\n",
    "    info = pd.DataFrame(columns=[\"GISAID Accession ID\", \"Adenine (A)\", \"Thymine (T)\", \"Guanine (G)\", \"Cytosine (C)\"])\n",
    "\n",
    "    info['GISAID Accession ID'] = nucleotide_counts_df['GISAID Accession ID']\n",
    "    info[\"Adenine (A)\"] = nucleotide_counts_df['A']\n",
    "    info[\"Thymine (T)\"] = nucleotide_counts_df['T']\n",
    "    info[\"Guanine (G)\"] = nucleotide_counts_df['G']\n",
    "    info[\"Cytosine (C)\"] = nucleotide_counts_df['C']\n",
    "    \n",
    "else:\n",
    "    info = pd.DataFrame(columns=[\"Adenine (A)\", \"Thymine (T)\", \"Guanine (G)\", \"Cytosine (C)\"])\n",
    "\n",
    "    info.loc[0] = [list(all_sequences.values())[0].count(\"A\"),list(all_sequences.values())[0].count(\"T\"),\n",
    "                       list(all_sequences.values())[0].count(\"G\"),list(all_sequences.values())[0].count(\"C\")]\n",
    "    \n",
    "for aa in amino_acids:\n",
    "    info[aa] = amino_acids_counts[aa]\n",
    "info.to_csv(path+variant_name+\"_info_sequences.csv\")\n",
    "info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
